{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZfaoZhJGVG2t8/RcMgdxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rithin353/RITHIN-/blob/main/CAPSTONE_PROJECT_TEAM_87.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sVDc_lx0mLz"
      },
      "outputs": [],
      "source": [
        "# Tampered Image Detection using VGG-16 with User Interface - Complete Google Colab Implementation\n",
        "# Based on the capstone project report with interactive UI\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 1: SETUP AND IMPORTS\n",
        "# ========================================================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install tensorflow keras opencv-python matplotlib seaborn scikit-learn\n",
        "!pip install pillow numpy pandas ipywidgets\n",
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import base64\n",
        "import time\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 2: DATASET CREATION AND PREPARATION\n",
        "# ========================================================================================\n",
        "\n",
        "def create_synthetic_dataset():\n",
        "    \"\"\"\n",
        "    Create a synthetic dataset with authentic and tampered images\n",
        "    \"\"\"\n",
        "    # Create directories\n",
        "    os.makedirs('dataset/authentic', exist_ok=True)\n",
        "    os.makedirs('dataset/tampered', exist_ok=True)\n",
        "\n",
        "    print(\"üì• Downloading sample images for dataset creation...\")\n",
        "\n",
        "    # Download some sample images from the internet (using free stock photos)\n",
        "    sample_urls = [\n",
        "        \"https://picsum.photos/400/300?random=1\",\n",
        "        \"https://picsum.photos/400/300?random=2\",\n",
        "        \"https://picsum.photos/400/300?random=3\",\n",
        "        \"https://picsum.photos/400/300?random=4\",\n",
        "        \"https://picsum.photos/400/300?random=5\",\n",
        "        \"https://picsum.photos/400/300?random=6\",\n",
        "        \"https://picsum.photos/400/300?random=7\",\n",
        "        \"https://picsum.photos/400/300?random=8\",\n",
        "        \"https://picsum.photos/400/300?random=9\",\n",
        "        \"https://picsum.photos/400/300?random=10\"\n",
        "    ]\n",
        "\n",
        "    authentic_images = []\n",
        "\n",
        "    # Download authentic images\n",
        "    for i, url in enumerate(sample_urls):\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img_path = f'dataset/authentic/authentic_{i+1}.jpg'\n",
        "            img.save(img_path)\n",
        "            authentic_images.append(img_path)\n",
        "            print(f\"‚úÖ Downloaded authentic image {i+1}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error downloading image {i+1}: {e}\")\n",
        "\n",
        "    return authentic_images\n",
        "\n",
        "def create_tampered_versions(authentic_images):\n",
        "    \"\"\"\n",
        "    Create tampered versions of authentic images using various techniques\n",
        "    \"\"\"\n",
        "    print(\"üîß Creating tampered versions...\")\n",
        "    tampered_count = 0\n",
        "\n",
        "    for i, img_path in enumerate(authentic_images):\n",
        "        try:\n",
        "            # Read the image\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Technique 1: Copy-Move forgery (duplicate a region)\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            # Select random region to copy\n",
        "            x1, y1 = np.random.randint(0, w//3), np.random.randint(0, h//3)\n",
        "            x2, y2 = x1 + w//4, y1 + h//4\n",
        "            x3, y3 = np.random.randint(w//2, w-w//4), np.random.randint(h//2, h-h//4)\n",
        "\n",
        "            # Copy region\n",
        "            region = img[y1:y2, x1:x2].copy()\n",
        "            img[y3:y3+(y2-y1), x3:x3+(x2-x1)] = region\n",
        "\n",
        "            # Save tampered image\n",
        "            tampered_path = f'dataset/tampered/tampered_copymove_{i+1}.jpg'\n",
        "            cv2.imwrite(tampered_path, img)\n",
        "            tampered_count += 1\n",
        "\n",
        "            # Technique 2: Splicing (blend two images)\n",
        "            if i < len(authentic_images) - 1:\n",
        "                img2 = cv2.imread(authentic_images[i+1])\n",
        "                if img2 is not None:\n",
        "                    # Resize both images to same size\n",
        "                    img_resized = cv2.resize(img, (400, 300))\n",
        "                    img2_resized = cv2.resize(img2, (400, 300))\n",
        "\n",
        "                    # Create a mask for blending\n",
        "                    mask = np.zeros((300, 400), dtype=np.uint8)\n",
        "                    mask[100:200, 150:250] = 255\n",
        "\n",
        "                    # Apply the mask\n",
        "                    result = img_resized.copy()\n",
        "                    result[mask > 0] = img2_resized[mask > 0]\n",
        "\n",
        "                    tampered_path = f'dataset/tampered/tampered_splice_{i+1}.jpg'\n",
        "                    cv2.imwrite(tampered_path, result)\n",
        "                    tampered_count += 1\n",
        "\n",
        "            # Technique 3: Noise addition\n",
        "            img_noise = img.copy()\n",
        "            noise = np.random.normal(0, 25, img.shape).astype(np.uint8)\n",
        "            img_noise = cv2.add(img_noise, noise)\n",
        "\n",
        "            tampered_path = f'dataset/tampered/tampered_noise_{i+1}.jpg'\n",
        "            cv2.imwrite(tampered_path, img_noise)\n",
        "            tampered_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error creating tampered version of image {i+1}: {e}\")\n",
        "\n",
        "    print(f\"‚úÖ Created {tampered_count} tampered images\")\n",
        "    return tampered_count\n",
        "\n",
        "# Create the dataset\n",
        "print(\"üöÄ Creating synthetic dataset...\")\n",
        "authentic_images = create_synthetic_dataset()\n",
        "tampered_count = create_tampered_versions(authentic_images)\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 3: DATA PREPROCESSING AND LOADING\n",
        "# ========================================================================================\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocess image for VGG16 input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image\n",
        "        img = load_img(image_path, target_size=target_size)\n",
        "\n",
        "        # Convert to array\n",
        "        img_array = img_to_array(img)\n",
        "\n",
        "        # Normalize pixel values to [0, 1]\n",
        "        img_array = img_array / 255.0\n",
        "\n",
        "        return img_array\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error preprocessing image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_dataset():\n",
        "    \"\"\"\n",
        "    Load and prepare the complete dataset\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    filenames = []\n",
        "\n",
        "    print(\"üìÇ Loading dataset...\")\n",
        "\n",
        "    # Load authentic images\n",
        "    authentic_dir = 'dataset/authentic'\n",
        "    for filename in os.listdir(authentic_dir):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img_path = os.path.join(authentic_dir, filename)\n",
        "            img = preprocess_image(img_path)\n",
        "            if img is not None:\n",
        "                images.append(img)\n",
        "                labels.append(0)  # 0 for authentic\n",
        "                filenames.append(filename)\n",
        "\n",
        "    # Load tampered images\n",
        "    tampered_dir = 'dataset/tampered'\n",
        "    for filename in os.listdir(tampered_dir):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img_path = os.path.join(tampered_dir, filename)\n",
        "            img = preprocess_image(img_path)\n",
        "            if img is not None:\n",
        "                images.append(img)\n",
        "                labels.append(1)  # 1 for tampered\n",
        "                filenames.append(filename)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X = np.array(images)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    print(f\"üìä Dataset loaded: {len(X)} images\")\n",
        "    print(f\"   ‚úÖ Authentic images: {np.sum(y == 0)}\")\n",
        "    print(f\"   ‚ö†Ô∏è  Tampered images: {np.sum(y == 1)}\")\n",
        "\n",
        "    return X, y, filenames\n",
        "\n",
        "# Load the dataset\n",
        "X, y, filenames = load_dataset()\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 4: MODEL ARCHITECTURE (VGG-16 BASED)\n",
        "# ========================================================================================\n",
        "\n",
        "def create_vgg16_model(input_shape=(224, 224, 3), num_classes=2):\n",
        "    \"\"\"\n",
        "    Create VGG16-based model for tampered image detection\n",
        "    \"\"\"\n",
        "    print(\"üèóÔ∏è  Building VGG-16 based model...\")\n",
        "\n",
        "    # Load pre-trained VGG16 without top layers\n",
        "    base_model = VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape\n",
        "    )\n",
        "\n",
        "    # Freeze the base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom top layers\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_vgg16_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model created and compiled successfully!\")\n",
        "print(f\"üìà Total parameters: {model.count_params():,}\")\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 5: TRAINING AND EVALUATION\n",
        "# ========================================================================================\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"üìä Dataset split:\")\n",
        "print(f\"   üèãÔ∏è Training set: {len(X_train)} images\")\n",
        "print(f\"   üîç Validation set: {len(X_val)} images\")\n",
        "print(f\"   üß™ Test set: {len(X_test)} images\")\n",
        "\n",
        "# Data augmentation for training\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"üöÄ Starting model training...\")\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=16),\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    steps_per_epoch=len(X_train) // 16\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training completed!\")\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 6: MODEL EVALUATION AND VISUALIZATION\n",
        "# ========================================================================================\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\nüìä Final Test Results:\")\n",
        "print(f\"   üéØ Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"   üìâ Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes,\n",
        "                          target_names=['Authentic', 'Tampered']))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "           xticklabels=['Authentic', 'Tampered'],\n",
        "           yticklabels=['Authentic', 'Tampered'])\n",
        "plt.title('Confusion Matrix - Tampered Image Detection')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
        "plt.title('Model Accuracy Over Time')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
        "plt.title('Model Loss Over Time')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 7: PREDICTION FUNCTIONS\n",
        "# ========================================================================================\n",
        "\n",
        "def predict_image_authenticity(model, image_path, confidence_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Predict whether an image is authentic or tampered\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Preprocess the image\n",
        "        img = preprocess_image(image_path)\n",
        "        if img is None:\n",
        "            return None, None\n",
        "\n",
        "        # Add batch dimension\n",
        "        img_batch = np.expand_dims(img, axis=0)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = model.predict(img_batch, verbose=0)\n",
        "        confidence = np.max(prediction)\n",
        "        predicted_class = np.argmax(prediction)\n",
        "\n",
        "        # Interpret results\n",
        "        if predicted_class == 0:\n",
        "            result = \"AUTHENTIC\"\n",
        "        else:\n",
        "            result = \"TAMPERED\"\n",
        "\n",
        "        return result, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error predicting image: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def predict_uploaded_image(model, image_data):\n",
        "    \"\"\"\n",
        "    Predict authenticity of uploaded image data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert uploaded data to PIL Image\n",
        "        img = Image.open(BytesIO(image_data))\n",
        "\n",
        "        # Save temporarily\n",
        "        temp_path = \"temp_uploaded_image.jpg\"\n",
        "        img.save(temp_path)\n",
        "\n",
        "        # Make prediction\n",
        "        result, confidence = predict_image_authenticity(model, temp_path)\n",
        "\n",
        "        # Clean up\n",
        "        if os.path.exists(temp_path):\n",
        "            os.remove(temp_path)\n",
        "\n",
        "        return result, confidence, img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing uploaded image: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 8: USER INTERFACE COMPONENTS\n",
        "# ========================================================================================\n",
        "\n",
        "class TamperedImageDetectionUI:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.setup_ui()\n",
        "\n",
        "    def setup_ui(self):\n",
        "        \"\"\"Setup the user interface components\"\"\"\n",
        "        # Title and description\n",
        "        self.title = widgets.HTML(\n",
        "            value=\"\"\"\n",
        "            <div style=\"text-align: center; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "                        border-radius: 15px; margin-bottom: 20px; color: white;\">\n",
        "                <h1 style=\"margin: 0; font-size: 28px; font-weight: bold;\">üîç Tampered Image Detection System</h1>\n",
        "                <p style=\"margin: 10px 0 0 0; font-size: 16px;\">Using VGG-16 Convolutional Neural Network</p>\n",
        "                <p style=\"margin: 5px 0 0 0; font-size: 14px; opacity: 0.9;\">Upload an image to check if it's authentic or tampered</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Upload button\n",
        "        self.upload_btn = widgets.FileUpload(\n",
        "            accept='image/*',\n",
        "            multiple=False,\n",
        "            description='üì§ Upload Image',\n",
        "            style={'button_color': '#4CAF50'},\n",
        "            layout=widgets.Layout(width='200px', height='50px')\n",
        "        )\n",
        "\n",
        "        # Analyze button\n",
        "        self.analyze_btn = widgets.Button(\n",
        "            description='üî¨ Analyze Image',\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='200px', height='50px'),\n",
        "            style={'font_weight': 'bold'}\n",
        "        )\n",
        "\n",
        "        # Clear button\n",
        "        self.clear_btn = widgets.Button(\n",
        "            description='üóëÔ∏è Clear Results',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='200px', height='50px')\n",
        "        )\n",
        "\n",
        "        # Output area\n",
        "        self.output = widgets.Output()\n",
        "\n",
        "        # Bind events\n",
        "        self.analyze_btn.on_click(self.analyze_image)\n",
        "        self.clear_btn.on_click(self.clear_results)\n",
        "\n",
        "        # Create layout\n",
        "        buttons_box = widgets.HBox([\n",
        "            self.upload_btn,\n",
        "            self.analyze_btn,\n",
        "            self.clear_btn\n",
        "        ], layout=widgets.Layout(justify_content='center', margin='20px 0'))\n",
        "\n",
        "        self.ui = widgets.VBox([\n",
        "            self.title,\n",
        "            buttons_box,\n",
        "            self.output\n",
        "        ])\n",
        "\n",
        "    def analyze_image(self, btn):\n",
        "        \"\"\"Analyze the uploaded image\"\"\"\n",
        "        with self.output:\n",
        "            clear_output()\n",
        "\n",
        "            if not self.upload_btn.value:\n",
        "                print(\"‚ùå Please upload an image first!\")\n",
        "                return\n",
        "\n",
        "            print(\"üîÑ Analyzing image...\")\n",
        "\n",
        "            try:\n",
        "                # Get uploaded file\n",
        "                uploaded_file = list(self.upload_btn.value.values())[0]\n",
        "                image_data = uploaded_file['content']\n",
        "                filename = uploaded_file['metadata']['name']\n",
        "\n",
        "                # Predict\n",
        "                result, confidence, img = predict_uploaded_image(self.model, image_data)\n",
        "\n",
        "                if result is None:\n",
        "                    print(\"‚ùå Error processing the image!\")\n",
        "                    return\n",
        "\n",
        "                # Display results\n",
        "                self.display_results(result, confidence, img, filename)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error analyzing image: {e}\")\n",
        "\n",
        "    def display_results(self, result, confidence, img, filename):\n",
        "        \"\"\"Display the analysis results\"\"\"\n",
        "        # Create result styling based on prediction\n",
        "        if result == \"AUTHENTIC\":\n",
        "            status_color = \"#4CAF50\"  # Green\n",
        "            status_icon = \"‚úÖ\"\n",
        "            status_message = \"This image appears to be AUTHENTIC\"\n",
        "            recommendation = \"The image shows no signs of tampering or manipulation.\"\n",
        "        else:\n",
        "            status_color = \"#f44336\"  # Red\n",
        "            status_icon = \"‚ö†Ô∏è\"\n",
        "            status_message = \"This image appears to be TAMPERED\"\n",
        "            recommendation = \"The image shows signs of potential tampering or manipulation.\"\n",
        "\n",
        "        # Display HTML results\n",
        "        result_html = f\"\"\"\n",
        "        <div style=\"border: 3px solid {status_color}; border-radius: 15px; padding: 20px; margin: 20px 0; background-color: #f9f9f9;\">\n",
        "            <h2 style=\"color: {status_color}; text-align: center; margin-bottom: 20px;\">\n",
        "                {status_icon} ANALYSIS RESULTS\n",
        "            </h2>\n",
        "\n",
        "            <div style=\"text-align: center; margin-bottom: 20px;\">\n",
        "                <p style=\"font-size: 18px; margin: 10px 0;\"><strong>File:</strong> {filename}</p>\n",
        "                <p style=\"font-size: 20px; margin: 10px 0; color: {status_color};\"><strong>{status_message}</strong></p>\n",
        "                <p style=\"font-size: 16px; margin: 10px 0;\"><strong>Confidence:</strong> {confidence:.1%}</p>\n",
        "                <p style=\"font-size: 14px; margin: 15px 0; font-style: italic;\">{recommendation}</p>\n",
        "            </div>\n",
        "\n",
        "            <div style=\"background-color: {status_color}; height: 4px; border-radius: 2px; margin: 20px 0;\"></div>\n",
        "\n",
        "            <div style=\"text-align: center;\">\n",
        "                <p style=\"font-size: 12px; color: #666; margin: 10px 0;\">\n",
        "                    Analysis performed using VGG-16 Convolutional Neural Network<br>\n",
        "                    Confidence score indicates the model's certainty in its prediction\n",
        "                </p>\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        display(HTML(result_html))\n",
        "\n",
        "        # Display the image\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Uploaded Image: {filename}\\nPrediction: {result} (Confidence: {confidence:.1%})',\n",
        "                 fontsize=14, pad=20)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Add colored border around the plot\n",
        "        ax = plt.gca()\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor(status_color)\n",
        "            spine.set_linewidth(4)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Display additional technical details\n",
        "        tech_details = f\"\"\"\n",
        "        <div style=\"background-color: #e8f4fd; border: 1px solid #1976d2; border-radius: 8px; padding: 15px; margin: 20px 0;\">\n",
        "            <h3 style=\"color: #1976d2; margin-top: 0;\">üîß Technical Details</h3>\n",
        "            <ul style=\"margin: 10px 0;\">\n",
        "                <li><strong>Model Architecture:</strong> VGG-16 with custom classification layers</li>\n",
        "                <li><strong>Input Processing:</strong> Image resized to 224√ó224 pixels and normalized</li>\n",
        "                <li><strong>Detection Methods:</strong> Copy-move, Splicing, Noise analysis</li>\n",
        "                <li><strong>Confidence Threshold:</strong> Higher values indicate more certain predictions</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(HTML(tech_details))\n",
        "\n",
        "    def clear_results(self, btn):\n",
        "        \"\"\"Clear all results\"\"\"\n",
        "        with self.output:\n",
        "            clear_output()\n",
        "            print(\"üóëÔ∏è Results cleared! Ready for new analysis.\")\n",
        "\n",
        "    def display(self):\n",
        "        \"\"\"Display the complete UI\"\"\"\n",
        "        display(self.ui)\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 9: SAVE MODEL\n",
        "# ========================================================================================\n",
        "\n",
        "# Save the trained model\n",
        "model.save('tampered_image_detection_vgg16.h5')\n",
        "print(\"üíæ Model saved as 'tampered_image_detection_vgg16.h5'\")\n",
        "\n",
        "# Save with pickle (as mentioned in the project)\n",
        "with open('tampered_detection_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "print(\"üíæ Model also saved as 'tampered_detection_model.pkl'\")\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 10: DEMONSTRATION WITH SAMPLE IMAGES\n",
        "# ========================================================================================\n",
        "\n",
        "def show_sample_predictions():\n",
        "    \"\"\"Show predictions on sample images from the dataset\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä SAMPLE PREDICTIONS FROM DATASET\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Get some sample images\n",
        "    auth_files = [f\"dataset/authentic/{f}\" for f in os.listdir(\"dataset/authentic\")\n",
        "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:3]\n",
        "\n",
        "    tamp_files = [f\"dataset/tampered/{f}\" for f in os.listdir(\"dataset/tampered\")\n",
        "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:3]\n",
        "\n",
        "    sample_images = auth_files + tamp_files\n",
        "\n",
        "    # Create subplot\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, img_path in enumerate(sample_images[:6]):\n",
        "        # Load and display image\n",
        "        img = cv2.imread(img_path)\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Make prediction\n",
        "        result, confidence = predict_image_authenticity(model, img_path)\n",
        "\n",
        "        # Color based on result\n",
        "        color = 'green' if result == \"AUTHENTIC\" else 'red'\n",
        "\n",
        "        # Display\n",
        "        axes[i].imshow(img_rgb)\n",
        "        axes[i].set_title(f'{os.path.basename(img_path)}\\n{result}\\nConfidence: {confidence:.3f}',\n",
        "                         color=color, fontweight='bold')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "        # Add colored border\n",
        "        for spine in axes[i].spines.values():\n",
        "            spine.set_visible(True)\n",
        "            spine.set_edgecolor(color)\n",
        "            spine.set_linewidth(3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Sample Predictions from Training Dataset', fontsize=16, fontweight='bold', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "# Show sample predictions\n",
        "show_sample_predictions()\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 11: INITIALIZE USER INTERFACE\n",
        "# ========================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ INITIALIZING USER INTERFACE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create and display the UI\n",
        "ui = TamperedImageDetectionUI(model)\n",
        "ui.display()\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 12: ADDITIONAL UTILITIES\n",
        "# ========================================================================================\n",
        "\n",
        "def batch_analyze_images():\n",
        "    \"\"\"Function to analyze multiple images at once\"\"\"\n",
        "    print(\"\\nüì§ Upload multiple images for batch analysis:\")\n",
        "\n",
        "    multi_upload = widgets.FileUpload(\n",
        "        accept='image/*',\n",
        "        multiple=True,\n",
        "        description='Upload Images'\n",
        "    )\n",
        "\n",
        "    analyze_batch_btn = widgets.Button(\n",
        "        description='Analyze All',\n",
        "        button_style='info'\n",
        "    )\n",
        "\n",
        "    batch_output = widgets.Output()\n",
        "\n",
        "    def analyze_batch(btn):\n",
        "        with batch_output:\n",
        "            clear_output()\n",
        "\n",
        "            if not multi_upload.value:\n",
        "                print(\"‚ùå Please upload images first!\")\n",
        "                return\n",
        "\n",
        "            print(f\"üîÑ Analyzing {len(multi_upload.value)} images...\")\n",
        "\n",
        "            results = []\n",
        "            for filename, file_info in multi_upload.value.items():\n",
        "                try:\n",
        "                    result, confidence, img = predict_uploaded_image(model, file_info['content'])\n",
        "                    results.append({\n",
        "                        'filename': filename,\n",
        "                        'prediction': result,\n",
        "                        'confidence': confidence\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Error processing {filename}: {e}\")\n",
        "\n",
        "            # Display results table\n",
        "            if results:\n",
        "                df = pd.DataFrame(results)\n",
        "                print(\"üìä Batch Analysis Results:\")\n",
        "                print(df.to_string(index=False))\n",
        "\n",
        "                # Summary\n",
        "                authentic_count = sum(1 for r in results if r['prediction'] == 'AUTHENTIC')\n",
        "                tampered_count = len(results) - authentic_count\n",
        "\n",
        "                print(f\"\\nüìà Summary:\")\n",
        "                print(f\"   ‚úÖ Authentic: {authentic_count}\")\n",
        "                print(f\"   ‚ö†Ô∏è  Tampered: {tampered_count}\")\n",
        "\n",
        "    analyze_batch_btn.on_click(analyze_batch)\n",
        "\n",
        "    display(widgets.VBox([\n",
        "        widgets.HBox([multi_upload, analyze_batch_btn]),\n",
        "        batch_output\n",
        "    ]))\n",
        "\n",
        "print(\"\\nüéØ Additional Features:\")\n",
        "print(\"   ‚Ä¢ Single image analysis with detailed results\")\n",
        "print(\"   ‚Ä¢ Real-time confidence scoring\")\n",
        "print(\"   ‚Ä¢ Visual feedback with color-coded results\")\n",
        "print(\"   ‚Ä¢ Technical details and recommendations\")\n",
        "\n",
        "# ========================================================================================\n",
        "# PART 13: FINAL SUMMARY\n",
        "# ========================================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéâ PROJECT SUMMARY: TAMPERED IMAGE DETECTION WITH USER INTERFACE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"‚úÖ Dataset Created: {len(X)} images total\")\n",
        "print(f\"‚úÖ Model Architecture: VGG-16 with custom top layers\")\n",
        "print(f\"‚úÖ Training Completed: {len(history.epoch)} epochs\")\n",
        "print(f\"‚úÖ Final Test Accuracy: {test_accuracy:.1%}\")\n",
        "print(f\"‚úÖ Interactive UI: Ready for image upload and analysis\")\n",
        "print(f\"‚úÖ Model Saved: Multiple formats available\")\n",
        "\n",
        "print(\"\\nüéØ Key Features:\")\n",
        "print(\"   üì§ Easy image upload interface\")\n",
        "print(\"   üîç Real-time tampering detection\")\n",
        "print(\"   üìä Confidence scoring and detailed results\")\n",
        "print(\"   üé® Color-coded visual feedback\")\n",
        "print(\"   üìã Technical details and recommendations\")\n",
        "print(\"   üîß Batch processing capability\")\n",
        "\n",
        "print(\"\\nüí° How to Use:\")\n",
        "print(\"   1. Click 'üì§ Upload Image' to select your image\")\n",
        "print(\"   2. Click 'üî¨ Analyze Image' to detect tampering\")\n",
        "print(\"   3. View detailed results with confidence scores\")\n",
        "print(\"   4. Use 'üóëÔ∏è Clear Results' to start over\")\n",
        "\n",
        "print(\"\\nüèÜ Based on the capstone project by:\")\n",
        "print(\"   ‚Ä¢ RITHIN GOUD (2203A51353)\")\n",
        "print(\"   ‚Ä¢ VEDA SAI (2203A51472)\")\n",
        "print(\"   ‚Ä¢ SAVAN KUMAR (2203A51730)\")\n",
        "print(\"   ‚Ä¢ Kasturi Amarender (2203A51487)\")\n",
        "print(\"   ‚Ä¢ Sri Sri Manchena (2203A51181)\")\n",
        "\n",
        "print(\"\\n‚ú® Your tampered image detection system is ready!\")\n",
        "print(\"üöÄ Use the interface above to upload and analyze images!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Optional: Run batch analyzer\n",
        "print(\"\\nüîß Optional: Run batch analyzer for multiple images\")\n",
        "print(\"Uncomment the line below to enable batch processing:\")\n",
        "print(\"# batch_analyze_images()\")\n",
        "\n",
        "# Uncomment to enable batch processing\n",
        "# batch_analyze_images()"
      ]
    }
  ]
}